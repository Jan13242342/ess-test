from datetime import datetime, timedelta, date, time as dtime, timezone
from fastapi import FastAPI, Depends, HTTPException, Query
from fastapi.responses import JSONResponse
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy import text, func
from pydantic import BaseModel, Field
from typing import Optional, List
import asyncio
import json
import decimal

from deps import get_current_user
from config import DATABASE_URL, DEVICE_FRESH_SECS, ALARM_HISTORY_RETENTION_DAYS, RPC_LOG_RETENTION_DAYS

app = FastAPI(title="ESS Realtime API", version="1.0.0")

engine = create_async_engine(DATABASE_URL, pool_pre_ping=True)

# ÊîæÂà∞ÂâçÈù¢Ôºå‰æõ routers ÂØºÂÖ•
async_session = async_sessionmaker(engine, expire_on_commit=False)

# ---------------- ÂÖ¨ÂÖ±Ê®°Âûã‰∏éÂ∏∏Èáè ----------------

COLUMNS = """
r.device_id, d.device_sn, r.updated_at,
r.soc, r.soh, r.pv, r.load, r.grid, r.grid_q, r.batt,
r.ac_v, r.ac_f, r.v_a, r.v_b, r.v_c, r.i_a, r.i_b, r.i_c,
r.p_a, r.p_b, r.p_c, r.q_a, r.q_b, r.q_c,
r.e_pv_today, r.e_load_today, r.e_charge_today, r.e_discharge_today
"""

def online_flag(updated_at: datetime, fresh_secs: int) -> bool:
    if updated_at.tzinfo is None:
        updated_at = updated_at.replace(tzinfo=timezone.utc)
    return (datetime.now(timezone.utc) - updated_at) <= timedelta(seconds=fresh_secs)

# ---------------- ÊåÇËΩΩÊãÜÂàÜÂêéÁöÑË∑ØÁî± ----------------
from routers import user as user_router, admin as admin_router, ota as ota_router, rpc as rpc_router, alarm as alarm_router, auth as auth_router
app.include_router(auth_router.router)
app.include_router(user_router.router)
app.include_router(admin_router.router)
app.include_router(ota_router.router)
app.include_router(rpc_router.router)
app.include_router(alarm_router.router)

# ÁÆ°ÁêÜÂëò/ÂÆ¢ÊúçÂÖ±Áî®ÔºöÊ†πÊçÆËÆæÂ§áSNËé∑ÂèñÂÆûÊó∂Êï∞ÊçÆ
@app.get(
    "/api/v1/realtime/by_sn/{device_sn}",
    tags=["ÁÆ°ÁêÜÂëò/ÂÆ¢Êúç | Admin/Service"],
    summary="Ê†πÊçÆËÆæÂ§áSNËé∑ÂèñÂÆûÊó∂Êï∞ÊçÆ | Get Realtime Data by Device SN",
    description="""
**ÊùÉÈôêË¶ÅÊ±Ç | Required Role**: admin, service, support

Ê†πÊçÆËÆæÂ§áÂ∫èÂàóÂè∑Êü•ËØ¢ËØ•ËÆæÂ§áÁöÑÂÆûÊó∂Êï∞ÊçÆÔºàÂåÖÂê´Âú®Á∫øÁä∂ÊÄÅÔºâ„ÄÇ

Query real-time data by device serial number (including online status).
"""
)
async def get_realtime_by_sn(device_sn: str, user=Depends(get_current_user)):
    if user["role"] not in ("admin", "service", "support"):
        raise HTTPException(status_code=403, detail="Êó†ÊùÉÈôê")
    sql = text(f"""
        SELECT {COLUMNS}
        FROM ess_realtime_data r
        JOIN devices d ON r.device_id = d.id
        WHERE d.device_sn=:sn
    """)
    async with engine.connect() as conn:
        row = (await conn.execute(sql, {"sn": device_sn})).mappings().first()
        if not row:
            raise HTTPException(status_code=404, detail="ÂÆûÊó∂Êï∞ÊçÆ‰∏çÂ≠òÂú®")
    d = dict(row)
    d["online"] = online_flag(d["updated_at"], DEVICE_FRESH_SECS)
    return d

# ---------------- ÂéÜÂè≤ËÉΩËÄóËÅöÂêà ----------------

class HistoryDataAgg(BaseModel):
    device_id: int
    device_sn: str
    day: Optional[date] = None
    hour: Optional[datetime] = None
    month: Optional[date] = None
    charge_wh_total: Optional[int]
    discharge_wh_total: Optional[int]
    pv_wh_total: Optional[int]
    grid_wh_total: Optional[int]
    load_wh_total: Optional[int]

class HistoryAggListResponse(BaseModel):
    items: List[HistoryDataAgg]
    page: int
    page_size: int
    total: int

@app.get(
    "/api/v1/history/admin/by_sn",
    response_model=HistoryAggListResponse,
    tags=["ÁÆ°ÁêÜÂëò/ÂÆ¢Êúç | Admin/Service"],
    summary="ÁÆ°ÁêÜÂëòÊåâËÆæÂ§áSNÊü•ËØ¢ÂéÜÂè≤ËÉΩËÄóËÅöÂêàÊï∞ÊçÆ",
    description="""
**ÊùÉÈôêË¶ÅÊ±Ç | Required Role**: admin, service, support

ÁÆ°ÁêÜÂëòÊàñÂÆ¢ÊúçÂèØÈÄöËøáËÆæÂ§áSNÊü•ËØ¢ËØ•ËÆæÂ§áÁöÑÂéÜÂè≤ËÉΩËÄóËÅöÂêàÊï∞ÊçÆÔºåÊîØÊåÅÊåâÂõ∫ÂÆöÂë®ÊúüÊàñÊåáÂÆöÊó•ÊúüÔºàÊåâÂ∞èÊó∂ÔºâËÅöÂêà„ÄÇ

Admin/Service/Support can query device historical energy aggregation data by device SN.

**ÊîØÊåÅÁöÑËÅöÂêàÂë®Êúü | Supported Periods**:
- `today`: ‰ªäÊó•ÊåâÂ∞èÊó∂ËÅöÂêà | Hourly aggregation for today
- `week`: Êú¨Âë®ÊåâÂ§©ËÅöÂêà | Daily aggregation for this week
- `month`: Êú¨ÊúàÊåâÂ§©ËÅöÂêà | Daily aggregation for this month
- `quarter`: Êú¨Â≠£Â∫¶ÊåâÊúàËÅöÂêà | Monthly aggregation for this quarter
- `year`: Êú¨Âπ¥ÊåâÊúàËÅöÂêà | Monthly aggregation for this year
- `date`: ÊåáÂÆöÊó•ÊúüÊåâÂ∞èÊó∂ËÅöÂêàÔºàË¶ÜÁõñperiodÔºâ| Hourly aggregation for specific date (overrides period)
"""
)
async def admin_history_by_sn(
    device_sn: str = Query(..., description="ËÆæÂ§áÂ∫èÂàóÂè∑"),
    period: str = Query("today", description="ËÅöÂêàÂë®Êúü: today/week/month/quarter/yearÔºåÈªòËÆ§today"),
    date: Optional[date] = Query(None, description="ÊåáÂÆöÊó•ÊúüÔºàYYYY-MM-DDÔºâÔºåÊåâËØ•Êó•ÊúüÊåâÂ∞èÊó∂ËÅöÂêàÔºå‰ºòÂÖà‰∫éperiod | Specific date (YYYY-MM-DD), aggregate by hour for that day, takes precedence over period"),
    page: int = Query(1, ge=1, description="È°µÁ†Å"),
    page_size: int = Query(20, ge=1, le=200, description="ÊØèÈ°µÊï∞Èáè"),
    admin=Depends(get_current_user)
):
    # Âè™ÂÖÅËÆ∏ÁÆ°ÁêÜÂëòÂíåÂÆ¢ÊúçËÆøÈóÆ
    if admin["role"] not in ("admin", "service", "support"):
        raise HTTPException(status_code=403, detail="Êó†ÊùÉÈôê")
    async with engine.connect() as conn:
        device_row = (await conn.execute(
            text("SELECT id, device_sn FROM devices WHERE device_sn=:sn"),
            {"sn": device_sn}
        )).mappings().first()
        if not device_row:
            raise HTTPException(status_code=404, detail="ËÆæÂ§á‰∏çÂ≠òÂú®")
        device_id = device_row["id"]
        device_sn_map = {device_id: device_sn}
    now = datetime.now(timezone.utc)
    if date:
        start = datetime.combine(date, dtime.min).replace(tzinfo=timezone.utc)
        end = datetime.combine(date, dtime.max).replace(tzinfo=timezone.utc)
        group_expr = "date_trunc('hour', ts)"
        group_label = "hour"
    else:
        # Âêå‰∏ä period ÈÄªËæë
        if period == "today":
            start = now.replace(hour=0, minute=0, second=0, microsecond=0)
            end = now.replace(hour=23, minute=59, second=59, microsecond=999999)
            group_expr = "date_trunc('hour', ts)"
            group_label = "hour"
        elif period == "week":
            start_of_week = now - timedelta(days=now.weekday())
            start = start_of_week.replace(hour=0, minute=0, second=0, microsecond=0)
            end = start + timedelta(days=6, hours=23, minutes=59, seconds=59, microseconds=999999)
            group_expr = "date_trunc('day', ts)"
            group_label = "day"
        elif period == "month":
            start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
            next_month = (now.replace(day=28) + timedelta(days=4)).replace(day=1)
            end = next_month - timedelta(seconds=1)
            group_expr = "date_trunc('day', ts)"
            group_label = "day"
        elif period == "quarter":
            quarter = (now.month - 1) // 3 + 1
            start_month = (quarter - 1) * 3 + 1
            start = now.replace(month=start_month, day=1, hour=0, minute=0, second=0, microsecond=0)
            end_month = quarter * 3
            next_quarter = start.replace(month=end_month + 1, day=1) if end_month < 12 else start.replace(year=start.year + 1, month=1, day=1)
            end = next_quarter - timedelta(seconds=1)
            group_expr = "date_trunc('month', ts)"
            group_label = "month"
        elif period == "year":
            start = now.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0)
            end = now.replace(month=12, day=31, hour=23, minute=59, second=59, microsecond=999999)
            group_expr = "date_trunc('month', ts)"
            group_label = "month"
        else:
            raise HTTPException(status_code=400, detail="Êó†ÊïàÁöÑ period ÂÄº")
    params = {"id0": device_id, "start": start, "end": end}
    where = ["device_id = :id0", "ts >= :start", "ts <= :end"]
    cond = "WHERE " + " AND ".join(where) if where else ""
    offset = (page - 1) * page_size
    async with engine.connect() as conn:
        count_sql = text(f"""
            SELECT COUNT(*) FROM (
                SELECT {group_expr} AS {group_label}, device_id
                FROM history_energy
                {cond}
                GROUP BY device_id, {group_label}
            ) t
        """)
        query_sql = text(f"""
            SELECT
                device_id,
                {group_expr} AS {group_label},
                SUM(charge_wh_total) AS charge_wh_total,
                SUM(discharge_wh_total) AS discharge_wh_total,
                SUM(pv_wh_total) AS pv_wh_total,
                SUM(grid_wh_total) AS grid_wh_total,
                SUM(load_wh_total) AS load_wh_total      -- Êñ∞Â¢û
            FROM history_energy
            {cond}
            GROUP BY device_id, {group_label}
            ORDER BY {group_label} DESC
            LIMIT :limit OFFSET :offset
        """)
        total = (await conn.execute(count_sql, params)).scalar_one()
        rows = (await conn.execute(query_sql, {**params, "limit": page_size, "offset": offset})).mappings().all()
    items = []
    for r in rows:
        d = dict(r)
        d["device_sn"] = device_sn_map.get(d["device_id"], "")
        # Âè™‰øùÁïôÂΩìÂâçËÅöÂêàÁ≤íÂ∫¶ÁöÑÂ≠óÊÆµ
        if group_label == "hour":
            d["hour"] = d.pop("hour")
            d["day"] = None
            d["month"] = None
        elif group_label == "day":
            d["day"] = d.pop("day")
            d["hour"] = None
            d["month"] = None
        elif group_label == "month":
            d["month"] = d.pop("month")
            d["hour"] = None
            d["day"] = None
        items.append(d)
    return {"items": items, "page": page, "page_size": page_size, "total": total}

@app.get(
    "/api/v1/db/metrics",
    tags=["ÁÆ°ÁêÜÂëò/ÂÆ¢Êúç | Admin/Service"],
    summary="Êï∞ÊçÆÂ∫ìÂÅ•Â∫∑‰∏éÊÄßËÉΩÊåáÊ†á | Database Health & Performance Metrics",
    description="""
**ÊùÉÈôêË¶ÅÊ±Ç | Required Role**: admin, service

‰ªÖÁÆ°ÁêÜÂëòÂíåÂÆ¢ÊúçÂèØÁî®„ÄÇËøîÂõûÊï∞ÊçÆÂ∫ìËøûÊé•Êï∞„ÄÅÊ¥ªË∑ÉËøûÊé•„ÄÅÊÖ¢Êü•ËØ¢„ÄÅÁºìÂ≠òÂëΩ‰∏≠Áéá„ÄÅÊ≠ªÈîÅÊï∞„ÄÅÊÖ¢SQLÂéÜÂè≤Á≠âÂ§öÈ°πÊï∞ÊçÆÂ∫ìÂÅ•Â∫∑‰∏éÊÄßËÉΩÊåáÊ†á„ÄÇ

Admin and service only. Returns database connection count, active connections, slow queries, cache hit rate, deadlocks, slow SQL history and other health/performance metrics.

üìä **ËøîÂõûÊåáÊ†á | Metrics Returned**:
- ËøûÊé•Êï∞ÁªüËÆ°ÔºàÊÄªÊï∞/Ê¥ªË∑É/Á©∫Èó≤Ôºâ| Connection stats (total/active/idle)
- ÊÖ¢Êü•ËØ¢ÂàóË°®Ôºà>5ÁßíÔºâ| Slow queries (>5s)
- Êï∞ÊçÆÂ∫ìÂ§ßÂ∞è & Ë°®Â§ßÂ∞è | DB size & table sizes
- ÁºìÂ≠òÂëΩ‰∏≠Áéá | Cache hit rate
- Ê≠ªÈîÅÊï∞Èáè | Deadlock count
- ÂéÜÂè≤ÊÖ¢SQLÁªüËÆ° | Historical slow SQL stats
"""
)
async def db_metrics(user=Depends(get_current_user)):
    # Âè™ÂÖÅËÆ∏ÁÆ°ÁêÜÂëòÂíåÂÆ¢ÊúçËÆøÈóÆ
    if user["role"] not in ("admin", "service"):
        raise HTTPException(status_code=403, detail="Êó†ÊùÉÈôê")

    async with engine.connect() as conn:
        # ÂΩìÂâçËøûÊé•Êï∞
        conn_count = (await conn.execute(text("SELECT count(*) FROM pg_stat_activity"))).scalar_one()

        def safe_dict(row):
            d = dict(row)
            if "client_addr" in d and d["client_addr"] is not None:
                d["client_addr"] = str(d["client_addr"])
            if "duration" in d and d["duration"] is not None:
                d["duration"] = str(d["duration"])
            return d

        # Ê¥ªË∑ÉËøûÊé•ËØ¶ÊÉÖÔºàÈùû idleÔºâ
        active_sql = text("""
            SELECT pid, usename, application_name, client_addr, state, query, now() - query_start AS duration
            FROM pg_stat_activity
            WHERE state != 'idle'
            ORDER BY duration DESC
            LIMIT 20
        """)
        active_rows = (await conn.execute(active_sql)).mappings().all()
        active_connections = [safe_dict(row) for row in active_rows]

        # ÊÖ¢Êü•ËØ¢ÔºàËøêË°åË∂ÖËøá5ÁßíÁöÑÔºâ
        slow_sql = text("""
            SELECT pid, usename, application_name, client_addr, state, query, now() - query_start AS duration
            FROM pg_stat_activity
            WHERE state != 'idle' AND now() - query_start > interval '5 seconds'
            ORDER BY duration DESC
            LIMIT 20
        """)
        slow_rows = (await conn.execute(slow_sql)).mappings().all()
        slow_queries = [safe_dict(row) for row in slow_rows]

        # Êï∞ÊçÆÂ∫ìÊÄªÂ§ßÂ∞è
        db_size = (await conn.execute(text("SELECT pg_size_pretty(pg_database_size(current_database()))"))).scalar_one()

        # ÊØè‰∏™Ë°®ÁöÑÂ§ßÂ∞èÔºàÂâç10Â§ßË°®Ôºâ
        table_sizes = (await conn.execute(text("""
            SELECT relname AS table, pg_size_pretty(pg_total_relation_size(relid)) AS size
            FROM pg_catalog.pg_statio_user_tables
            ORDER BY pg_total_relation_size(relid) DESC
            LIMIT 10
        """))).mappings().all()
        table_sizes = [dict(row) for row in table_sizes]

        # ÁºìÂ≠òÂëΩ‰∏≠Áéá
        hit_rate = (await conn.execute(text("""
            SELECT
                ROUND(SUM(blks_hit) / NULLIF(SUM(blks_hit) + SUM(blks_read),0)::numeric, 4) AS hit_rate
            FROM pg_stat_database
        """))).scalar_one()

        # Ê≠ªÈîÅÊï∞
        deadlocks = (await conn.execute(text("""
            SELECT SUM(deadlocks) FROM pg_stat_database
        """))).scalar_one()

        # ‰∫ãÂä°Êï∞ÔºàÂΩìÂâçÊ¥ªË∑É‰∫ãÂä°Êï∞Ôºâ
        tx_count = (await conn.execute(text("""
            SELECT count(*) FROM pg_stat_activity WHERE state = 'active'
        """))).scalar_one()

        # ÂΩìÂâçÁ≠âÂæÖÁöÑÊü•ËØ¢Êï∞
        waiting_count = (await conn.execute(text("""
            SELECT count(*) FROM pg_stat_activity WHERE wait_event IS NOT NULL
        """))).scalar_one()

        # Êï∞ÊçÆÂ∫ìÂêØÂä®Êó∂Èó¥
        start_time = (await conn.execute(text("""
            SELECT pg_postmaster_start_time()
        """))).scalar_one()

        # ÊúçÂä°Âô®ÁâàÊú¨
        version = (await conn.execute(text("SHOW server_version"))).scalar_one()

        # ÊúÄÂ§ßËøûÊé•Êï∞
        max_conn = (await conn.execute(text("SHOW max_connections"))).scalar_one()

        # ÂΩìÂâçÁ©∫Èó≤ËøûÊé•Êï∞
        idle_conn = (await conn.execute(
            text("SELECT count(*) FROM pg_stat_activity WHERE state = 'idle'")
        )).scalar_one()

        # ÂéÜÂè≤ÊÖ¢SQLÁªüËÆ°ÔºàPostgreSQL 13+ Â≠óÊÆµÔºâ
        try:
            stat_sql = text("""
                SELECT
                    query,
                    calls,
                    total_exec_time,
                    mean_exec_time,
                    max_exec_time
                FROM pg_stat_statements
                WHERE calls > 10
                ORDER BY mean_exec_time DESC
                LIMIT 10
            """)
            stat_rows = (await conn.execute(stat_sql)).mappings().all()
            slow_sql_history = [dict(row) for row in stat_rows]
        except Exception:
            await conn.rollback()
            slow_sql_history = []

    result = {
        "connection_count": conn_count,
        "active_connections": active_connections,
        "slow_queries": slow_queries,
        "db_size": db_size,
        "table_sizes": table_sizes,
        "cache_hit_rate": float(hit_rate) if hit_rate is not None else None,
        "deadlocks": deadlocks,
        "active_tx_count": tx_count,
        "waiting_query_count": waiting_count,
        "start_time": str(start_time),
        "server_version": version,
        "max_connections": int(max_conn),
        "idle_connections": idle_conn,
        "slow_sql_history": slow_sql_history
    }
    return JSONResponse(convert_decimal(result))

def convert_decimal(obj):
    if isinstance(obj, list):
        return [convert_decimal(i) for i in obj]
    elif isinstance(obj, dict):
        return {k: convert_decimal(v) for k, v in obj.items()}
    elif isinstance(obj, decimal.Decimal):
        # ‰Ω†ÂèØ‰ª•Ê†πÊçÆÂÆûÈôÖÊÉÖÂÜµËΩ¨ float Êàñ int
        return float(obj)
    else:
        return obj

async def cleanup_alarm_history():
    while True:
        await asyncio.sleep(86400)  # ÊØèÂ§©ËøêË°å‰∏ÄÊ¨°
        try:
            cutoff = datetime.now(timezone.utc) - timedelta(days=ALARM_HISTORY_RETENTION_DAYS)
            async with engine.begin() as conn:
                await conn.execute(
                    text("DELETE FROM alarm_history WHERE archived_at < :cutoff"),
                    {"cutoff": cutoff}
                )
        except Exception as e:
            print(f"Ê∏ÖÁêÜÂéÜÂè≤Êä•Ë≠¶Â§±Ë¥•: {e}")

async def cleanup_rpc_logs():
    while True:
        await asyncio.sleep(86400)  # ÊØèÂ§©ËøêË°å‰∏ÄÊ¨°
        try:
            cutoff = datetime.now(timezone.utc) - timedelta(days=RPC_LOG_RETENTION_DAYS)
            async with engine.begin() as conn:
                await conn.execute(
                    text("DELETE FROM device_rpc_change_log WHERE created_at < :cutoff"),
                    {"cutoff": cutoff}
                )
        except Exception as e:
            print(f"Ê∏ÖÁêÜRPCÊó•ÂøóÂ§±Ë¥•: {e}")

@app.on_event("startup")
async def startup_event():
    asyncio.create_task(cleanup_rpc_logs())
    asyncio.create_task(cleanup_alarm_history())

@app.get(
    "/api/v1/devices/online_summary",
    tags=["ÁÆ°ÁêÜÂëò/ÂÆ¢Êúç | Admin/Service"],
    summary="ËÆæÂ§áÂú®Á∫øÁªüËÆ° | Device Online Summary",
    description="""
**ÊùÉÈôêË¶ÅÊ±Ç | Required Role**: admin, service, support

ËøîÂõûËÆæÂ§áÊÄªÊï∞„ÄÅÂú®Á∫øÊï∞„ÄÅÁ¶ªÁ∫øÊï∞ÔºõÊåâÊúÄËøë60ÁßíÂÜÖÊúâ‰∏äÊä•Âà§ÂÆö‰∏∫Âú®Á∫ø„ÄÇ

Returns total devices, online devices, and offline devices. Devices with data reported within the last 60 seconds are considered online.

üìù **Âú®Á∫øÂà§Êñ≠Ê†áÂáÜ | Online Criteria**: 60ÁßíÂÜÖÊúâÊï∞ÊçÆ‰∏äÊä• | Data reported within 60 seconds
"""
)
async def devices_online_summary(
    user=Depends(get_current_user)
):
    if user["role"] not in ("admin", "service", "support"):
        raise HTTPException(status_code=403, detail="Êó†ÊùÉÈôê")

    fresh = 60  # Âõ∫ÂÆö60Áßí

    async with engine.connect() as conn:
        total_devices = (await conn.execute(
            text("SELECT COUNT(*) FROM devices")
        )).scalar_one()

        online_devices = (await conn.execute(
            text("""
                WITH latest AS (
                  SELECT device_id, MAX(updated_at) AS updated_at
                  FROM ess_realtime_data

                  GROUP BY device_id
                )
                SELECT COUNT(*)
                FROM devices d
                LEFT JOIN latest r ON r.device_id = d.id
                WHERE r.updated_at IS NOT NULL
                  AND r.updated_at >= now() - make_interval(secs => :fresh)
            """),
            {"fresh": fresh}
        )).scalar_one()

    offline_devices = max(0, int(total_devices) - int(online_devices))
    return {
        "total_devices": int(total_devices),
        "online_devices": int(online_devices),
        "offline_devices": offline_devices,
        "fresh_secs": fresh
    }
